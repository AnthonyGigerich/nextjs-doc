<img src="/images/docs/mediation-algo/1.png" alt="I am more than my algorythm" style="width:1200px"/>

> Loin de l’image d’un algorithme comme d’une “boîte noire” jugée inaccessible et secrète, nous sommes tous déjà témoins de la présence des algorithmes dans nos vies : sur un bureau traîne un formulaire avec en son sein une note sur le calcul d’une police d’assurance ; sous le pas de la porte attend un courrier criblé de critères pondérés qui conditionnent une aide à l’installation de panneaux solaires ; sur le canapé jonche un prospectus vantant les mérites de nouvelles techniques de réduction du gaspillage alimentaire d’un restaurant d’entreprise.

La liste des instructions algorithmiques qui parsèment notre quotidien pourrait continuer à l’infini. Bien que nous ayons encore de la peine à saisir leurs complexités et abstractions, les algorithmes sont à notre échelle. **Comment appréhender leurs effets et déjouer les problèmes qu’ils génèrent ? Avec comme intuition l'idée que nous devrions tous pouvoir saisir leurs manifestations dans le tissu de nos vies, Datactivist et la Mednum lancent un projet de recherche-action qui vise à expérimenter des démarches de médiation aux algorithmes.** Nous souhaitons sortir d’un sentiment d’inconfort ou d’incompréhension face aux systèmes algorithmiques qui  prennent part à des prises de décisions dans de nombreux domaines de la vie sociale.

## **Un contexte juridique favorable à la transparence algorithmique**

Les discussions sur l'utilisation préjudiciable des algorithmes dans les institutions françaises ont commencé à recevoir une attention nationale lorsqu'en 2017 la "controverse APB" (“Admission Post-Bac”). Ce système algorithmique à grande échelle était responsable, chaque année, de l'accès à plus de 10 000 formations de l'enseignement supérieur de 850 000 lycéens. Cette controverse provoquera des dizaines d'articles dans les médias ainsi que des débats au Sénat et à l'Assemblée nationale. Dans un premier temps, les étudiants et étudiantes ont contesté l'algorithme au motif que leurs notes n'étaient pas prises en compte dans leurs affectations et qu'ils étaient répartis de manière aléatoire dans les formations de l'enseignement supérieur.

Même si APB a été transformé et remplacé par un autre système en janvier 2018 (il s'appelle désormais Parcoursup), les critiques fusent, la controverse perdure avec des débats animés qui soulignent que la demande de transparence algorithmique reste pressante.

La controverse sur APB a suscité des questions sur une série d'autres algorithmes utilisés par les administrations françaises.

> Ce scandale a ouvert la voie à une prise de conscience tant sociétale qu’étatique du rôle des algorithmes dans le quotidien des Français et Françaises.

Afin d’améliorer les moyens d’information et de contestation des décisions algorithmiques des Français et Françaises — qui bien que peu automatisés, posent toutefois de nombreux problèmes — la loi pour une République numérique (dit Loi Lemaire), puis le Règlement sur la protection des données à caractère personnel (RGPD) ont introduit de nouvelles obligations pour les administrations utilisant des algorithmes dans le cadre de mission de service public.

Dans ce nouveau cadre légal bien résumé dans le [Guide des Algorithmes Publics](https://guides.etalab.gouv.fr/algorithmes/guide/) auquel notre chercheur Loup Cellard a contribué, on distingue :

- **Les obligations liées au traitement de données personnelles :** l'article 119 de la loi Informatique et Libertés **\[1\]**, qui s'applique tant au secteur public que privé, précise que "*toute personne physique justifiant de son identité a le droit d'interroger le responsable d'un traitement à caractère personnel en vue d'obtenir (...) les informations permettant de connaître et de contester la logique qui sous-tend **le traitement automatisé** en cas de décision prise sur le fondement de celui-ci et produisant des effets juridiques à l'égard de l'intéressé*".
- **Les obligations liées à l'ouverture des codes sources en lien notamment avec le plan d’action logiciels libres et communs numériques \[2\]**;
- **Les obligations spécifiques de transparence des algorithmes publics prévues par le code des relations entre le public et l'administration** (CRPA), et qui obligent à : fournir une information générale sur le traitement algorithmique (article L.312-1-3), faire figurer une mention explicite sur les supports de la prise de décision (article L.311-3-1), fournir une information individuelle à la demande de l'intéressé s'il en fait explicitement la demande (article R.311-3-1-2) **\[3\]**.

Grâce à ces dernières dispositions, des collectifs d’experts/expertes et de citoyens/citoyennes informées se sont mobilisés ces cinq dernières années afin de comprendre et parfois de tenter de contester le fonctionnement d’un certain nombre d’algorithmes utilisés par des administrations publiques **\[4\]** : [le calcul de la taxe d’habitation](https://wrap.warwick.ac.uk/152961/) ; l’arbre de décision qui priorise l’ordre d’intervention entre le Samu et les pompiers ; le calcul des retraites de la Caisse Interprofessionnelle de Prévoyance et d'Assurance Vieillesse des professions libérales (CIPAV) ou encore le calcul de l'Indemnité Spéciale d’Éloignement (ISE). Pôle Emploi-France Travail signale aussi les algorithmes qu’il utilise **\[5\]**.

%%Products:patchwork-algorithmes%%

Datactivist intervient sur la question de la transparence algorithmique depuis l’année 2020. Cet engagement a abouti à de nombreuses rencontres auprès d’acteurs et la conduite d’une mission d’accompagnement de la Métropole européenne de Lille (MEL) dans l’ouverture de ses algorithmes publics. Elle a abouti à [un inventaire des algorithmes publics de la MEL](https://opendata.lillemetropole.fr/explore/dataset/algorithmes-mel/information/?flg=fr-fr), [un retour d’expérience documenté](https://medium.com/datactivist/exp%C3%A9rimentation-douverture-des-algorithmes-publics-%C3%A0-la-m%C3%A9tropole-europ%C3%A9enne-de-lille-35c224053868) et [une méthodologie](https://opendatacanvas.org/transparence-algo) pas-à-pas pour l’ouverture de registres d’algorithmes publics (voir image ci-dessus). Dans un registre connexe, nous avons accompagné une start-up d’Etat dans la documentation des données et des algorithmes qui nourrissent l’outil de visualisation de la consommation et artificialisation des sols : Mon Diagnostic Artificialisation.

Malgré ces expériences fructueuses, **il nous semble que les cas d’ouverture des algorithmes ne suffisent pas du point de vue de l’usager** qui doit, même lorsque les obligations légales sont respectées, faire face à une complexité technique et procédurale qui maintient l’opacité des algorithmes publics. Une démarche alternative et complémentaire à la transparence s’impose.

## **Passer à la médiation des algorithmes : une nécessité pour les usagers et organisations.**

Notre approche consiste à envisager la médiation comme une dimension à part entière de la transparence algorithmique.

> La médiation consiste à remettre l'usager et l’usagère au centre d’un dispositif d’information et d’explication, sortir d'une approche experte et véritablement échanger avec les publics concernés de manière précise mais pédagogique.

L’enjeu est d'autant plus important que de nombreux travaux montrent que les traitements algorithmiques pénalisent davantage les plus précaires **\[6\]**. Celles et ceux qui, comme le disait l’anthropologue David Graeber, doivent déjà fournir un “travail interprétatif” conséquent des règles et procédures légales s’appliquant à eux de manières obscures et hasardeuses. **\[7\]** Dans un contexte “d’algorithmisation” croissante des administrations, le droit à l’explicabilité des algorithmes publics reste peu utilisé. Lorsque c’est le cas, il favorise davantage des publics experts de scientifiques et de journalistes, comme Loup Cellard (coordinateur du présent projet) a pu le montrer dans [une note de recherche pour Etalab](http://www.loupcellard.com/wp-content/uploads/2019/07/cellard_note_algo_public.pdf).

Faire une démarche auprès de la CADA demande une certaine compréhension des rouages administratifs et des subtilités algorithmiques **\[8\]**, ce qui constitue un frein à l’obtention d’information par des publics éloignés du numérique. De plus, le régulateur a des difficultés à faire face à l’augmentation des demandes **\[9\]**. Bien souvent les chercheurs, chercheuses et journalistes qui font ces demandes ne sont pas directement impactés par des calculs algorithmiques injustes. Ils et elles cherchent à obtenir des ressources pour leurs travaux, ou à démontrer la mise en conformité légale des administrations au regard de leurs obligations de transparence. Ces éléments concourent à penser qu’**il y a une fracture numérique de la transparence algorithmique qui se pose alors comme un enjeu central d'égalité \[10\]. Organiser davantage de dialogue et de médiation avec des publics en demande d’information aux sujets de ces traitements algorithmiques permettrait de rompre cette fracture.**

## **De premières expérimentations dans la médiation aux algorithmes**

Les algorithmes marquent une nouvelle frontière dans la médiation au numérique. La difficulté à les cerner vient de leurs caractères complexes : ils mettent en œuvres des règles (juridiques, sociales, fiscales ou économiques) qui doivent trouver une transcription en langage informatique ; manipulent des données (construites et formatées de manières bien particulières) et peuvent avoir de nombreuses manifestations (du logiciel de bureautique en passant par la grille de critères à points jusqu’à l’infrastructure d’apprentissage machine).

Ces diverses dimensions d’un algorithme font que le travail de sa description et explicitation auprès des publics débordent largement le champ de l’informatique pour toucher des enjeux de choix dans l’orientation des politiques publiques, mais aussi des questions de droit, de design d’interface ou de communication institutionnelle. **Expliquer un algorithme ne consiste donc pas simplement à expliquer son code ou ses mécanismes mathématiques et statistiques, mais à déplier le tissu social, technique et institutionnel qui le traverse.**

Le sujet de la médiation aux algorithmes a fait l’objet de très peu de recherches en France ou ailleurs. Une exception est le projet de recherche-action **Nos Systèmes** **\[11\]**, porté en 2017 par la Fondation Internet Nouvelle Génération (FING) et financé par le Secrétariat Général à la Modernisation de l'Action Publique (SGMAP). L’objectif du projet Nos Systèmes était : “*d’ouvrir un dialogue non technique avec la technique*”. **\[12\]**

Outre le projet de la FING, un ensemble d’initiatives éparses ont fait surface, qui ne se réclament pas explicitement de la médiation aux algorithmes bien qu’elles en explorent certaines dimensions. On peut les séparer en cinq catégories :

1. **les dispositifs d’amélioration de la relation clients-usagers.** Ex : sur le forum en ligne de la MGEN, des usagers s’interrogent sur le détail précis du calcul des participations forfaitaires et franchises médicales. **\[13\]**
2. **les simulateurs et démonstrateurs qui simulent des calculs ou l’obtention de droits.** Ex : [Mes Droits Sociaux](https://www.mesdroitssociaux.gouv.fr/accueil/?utm_source=mes-aides-accueil&utm_medium=alternative) pour le calcul des aides sociales, [1jeune1solution](https://mes-aides.1jeune1solution.beta.gouv.fr/?utm_source=mes-aides-accueil&utm_medium=alternative) pour les aides attribuées au moins de 30 ans. **\[14\]**
3. **les documentations d’algorithmes.** Ex : l’agence de biomédecine publie un guide pour comprendre le score qui détermine l'attribution de greffe du rein. **\[15\]**
4. **les ressources pédagogiques.** Ex : le projet **Algorithm & Data Literacy Project \[17\]** porté par l’UNESCO a produit un ensemble de guides pour mener des activités de sensibilisation aux algorithmes auprès de jeunes publics.
5. **les ateliers participatifs.** Ex : les ateliers Data Island de l’acteur de la médiation Fréquence Ecoles à propos des formes de recommandations, tri d’informations, et du rôle des algorithmes dans la publicité sur les réseaux sociaux **\[18\]**. Autre exemple, en 2018 et dans le cadre d’une collaboration avec Etalab, Loup Cellard a expérimenté [une méthode d'atelier](https://journals.sagepub.com/eprint/8ZYIWYGMVQ7WDTFNNVHW/full) qui visait à reconstruire le calcul de l’algorithme de la taxe d’habitation à partir de l’étude de véritable feuille d’imposition et de sa documentation technique (voir image ci-dessous).

<img src="/images/docs/mediation-algo/2.png" alt="tableau : données, ingrédients, gestes culaintes, types de traitements algorithmiques" width="1000"/>

*Affiche de l'atelier permettant d'écrire de haut en bas : données/ingrédients, gestes culinaires/types de traitements algorithmiques, et étapes culinaires/instructions algorithmiques — Réalisé par Loup Cellard et Simon Chignard.* En savoir plus dans [cet article](https://journals.sagepub.com/eprint/8ZYIWYGMVQ7WDTFNNVHW/full).

<br />Face aux contraintes organisationnelles, techniques ou “métiers” qui pèsent sur les professionnels déployant des algorithmes, et dans un contexte de difficile application des principes de transparence, nous aborderons la compréhension des algorithmes comme **un enjeu de montée en compétence et de dialogue qui doit passer par une approche centrée sur la médiation auprès des publics.**

Si le trait d’union entre médiation au numérique et transparence algorithmique est l’idée qu’un acte de communication doit s’établir depuis les concepteurs et responsables d’algorithmes vers les usagers, les modalités de cette communication diffèrent entre les deux approches.

> Nous proposons donc dans ce projet de répondre à **une grande question de recherche** **: quelles sont les conditions de possibilité des démarches de médiation aux algorithmes (si on les envisage comme des formes tantôt complémentaires tantôt antinomiques à des dispositifs de transparence) ?**

## **Pour étudier la médiation aux algorithmes : une enquête qualitative**

Ce travail de recherche repose sur une enquête socio-anthropologique, principalement qualitative, qui emprunte également des méthodes issues du design participatif. Elle se déroule sur la période 2024–2025. Plus précisément, nous nous appuierons sur :

- Des **entretiens semi-directifs** avec des concepteurs, responsables et usagers d’algorithmes et des acteurs et actrices de la médiation numérique,
- Des **observations** (y compris participantes, dans le cadre par exemple d’ateliers de design animés par les organisations partenaires du projet),
- Une **étude documentaire** (archives papier et en ligne produites par des concepteurs d’algorithmes, de la littérature sociologique sur la question et de la littérature grise produite par des ONG, think-tanks ou des groupes d’activistes).

<br />La médiation aux algorithmes requiert une forte dimension de mise en débat collective. Notre projet se veut aussi une contribution au tournant participatif de la gouvernance de l’intelligence artificielle. Ce tournant anime depuis maintenant deux ans les ambitions de nombreux mouvements de réformes qui visent à démocratiser et à ouvrir la conception des algorithmes à des publics non-experts. Ces méthodes participatives sont prometteuses dans la recherche, le développement et la gouvernance de l'IA car elles peuvent offrir des outils permettant d'anticiper, d'identifier et d'éviter ces dégâts.

Partenaire du projet, la Mednum (coopérative nationale de la médiation numérique) nous aidera à constituer des terrains d’enquêtes. La Mednum travaille avec des acteurs de terrain sur les questions de médiation et d'inclusion afin de faciliter les usages du numérique, la coopérative essaie de répondre à un enjeu d'exclusion massif avec 16 millions de personnes estimées en difficulté et qui font face une nouvelle forme d'exclusion.

À travers ses sociétaires, la Mednum nous permettra d’aller à la rencontre des médiateurs et médiatrices numériques de proximité en demande d’accompagnement sur la constitution de ressources pédagogiques et de méthodes pour mettre en débat les effets des systèmes algorithmiques. Grâce à ce projet de recherche, nous pourrons accompagner d’autres acteurs de la médiation numérique (*faites nous signe !*), et les aider à mieux s'emparer du sujet.

## **Devenez partenaire du projet !**

Pour mener à bien ce projet ambitieux et essentiel pour améliorer notre compréhension commune des algorithmes, nous avons besoin de votre soutien (financements, accès à des terrains d’enquêtes, aide à la diffusion de questionnaires, remontées de littérature sur le sujet…). Ce soutien nous permettra d’aboutir à plusieurs outils pratiques à destination des acteurs de la médiation :

- **Un Cahier d’inspiration/Collection de ressources.** En s’appuyant sur le début d’une enquête documentaire, cette publication présentera des exemples et bonnes pratiques d’explication et médiation aux algorithmes.
- **Un rapport documentant une série de cas d’études** (à partir des terrains partenaires). Suite aux observations effectuées auprès des organisations partenaires, nous produirons un document de présentation synthétique des cas étudiés.
- **Une méthodologie d’explicabilité et de médiation.** Nous présenterons aux partenaires une méthodologie d’explication et de médiation des algorithmes, qu’ils pourront tester en avant-première et que nous ajusterons au cours d’ateliers.

Une des premières actions du projet consiste à mieux connaître les questionnements des acteurs de la médiation concernant les algorithmes et identifier les pratiques existantes de médiation des algorithmes. La Mednum et Datactivist lancent un questionnaire à destination des acteurs de la médiation numérique pour mieux connaître leurs besoins et leurs pratiques en matière de médiation aux algorithmes.

→ Le questionnaire prendra au maximum 5 minutes de votre temps, merci beaucoup pour votre contribution ! A compléter ici : [__https://forms.fillout.com/t/e8jA4morX3us__](https://forms.fillout.com/t/e8jA4morX3us)

---

*Si vous souhaitez en savoir plus, n’hésitez pas à contacter Loup Cellard ([__loup@datactivist.coop__](mailto:loup@datactivist.coop)), Samuel Goëta ([__samuel@datactivist.coop__](mailto:samuel@datactivist.coop)) et Quitterie de Marignan ([__quitterie.demarignan@lamednum.coop__](mailto:quitterie.demarignan@lamednum.coop)).*

## Ressources complémentaires

%%Docs:experimentation-algo-lille,ameliorer-qualite-documentation%%

## Notes et références

| N° | Référence |
|----|-----------|
| 1 | Voir le texte de loi en ligne : “Loi n° 78-17 du 6 janvier 1978 relative à l'informatique, aux fichiers et aux libertés”, Legifrance, URL: [__https://www.legifrance.gouv.fr/loda/article_lc/LEGIARTI000037817721__](https://www.legifrance.gouv.fr/loda/article_lc/LEGIARTI000037817721) (consulté le 04/11/2023) |
| 2 | Voir ce guide en ligne : “Codes sources du secteur public : lesquels ouvrir, pourquoi et comment ?, Etalab, URL: ”[__https://guides.data.gouv.fr/anciens-guides/codes-sources-du-secteur-public-lesquels-ouvrir-pourquoi-et-comment__](https://guides.data.gouv.fr/anciens-guides/codes-sources-du-secteur-public-lesquels-ouvrir-pourquoi-et-comment) (consulté le 05/11/2023) |
| 3 | Ces éléments sont repris du guide des algorithmes publics : “Les algorithmes publics : enjeux et obligations”, Etalab, URL: [__https://guides.etalab.gouv.fr/algorithmes/guide/__](https://guides.etalab.gouv.fr/algorithmes/guide/)  (consulté le 05/11/2023) |
| 4 | Pour un bilan de ces demandes avant 2019 voir : Cellard, L. « Les demandes citoyennes de transparence au sujet des algorithmes publics ». Note de recherche pour Etalab, 2019. Et consulter la liste des algorithmes ouverts établi par Etalab. URL: [__https://github.com/etalab/algorithmes-publics/blob/master/liste.md__](https://github.com/etalab/algorithmes-publics/blob/master/liste.md)  (consulté le 05/11/2023) |
| 5 | <https://www.pole-emploi.fr/candidat/algorithmes.html> |
| 6 | Eubanks, V. (2018). Automating Inequality: How High-tech Tools Profile, Police, and Punish the Poor. New York, NY: St Martin’s Press.  Dubois, V. (2021). *Contrôler les assistés. Genèses et usages d’un mot d’ordre*, Paris, Raisons d’agir. |
| 7 | Graeber, D. (2015), *Bureaucratie*, Les liens qui libèrent. |
| 8 | Même si nul n'est censé ignorer la loi, il faut bien avouer que beaucoup de gens ignorent l'existence même de ces principes. |
| 9 | Source : [__https://www.economie.gouv.fr/daj/la-lettre-de-la-daj-ndeg361-est-parue__](https://www.economie.gouv.fr/daj/la-lettre-de-la-daj-ndeg361-est-parue) (consulté le 13/11/2023) |
| 10 | Nous insistons sur le fait qu’il y a une fracture numérique en soi sur le sujet de la transparence algorithmique qui touche des publics que l'on ne qualifient pas si facilement de “fragiles” (ex : chômeur de longue durée). Bien sûr ce phénomène tend à accentuer la fracture numérique des plus fragiles. |
| 11 | Voir la présentation du projet : “RENDRE LA COMPLEXITÉ INTELLIGIBLE OU DE LA RÉGULATION DES ALGORITHMES ”, FING, URL: [__https://fing.org/wp-content/uploads/2020/02/pistes-innovation-nossystemes-version-travail.pdf__](https://fing.org/wp-content/uploads/2020/02/pistes-innovation-nossystemes-version-travail.pdf) (consulté le 04/11/2023) |
| 12 | “RENDRE LA COMPLEXITÉ INTELLIGIBLE OU DE LA RÉGULATION DES ALGORITHMES ”, *Ibid.* |
| 13 | Source : “Récupération de participations forfaitaires précédentes TER, MGEN, URL : [__https://mgenetvous.mgen.fr/questions/1326119-recuperation-participations-forfaitaires-precedentes-ter__](https://mgenetvous.mgen.fr/questions/1326119-recuperation-participations-forfaitaires-precedentes-ter) (consulté le 01/11/2023) |
| 14 | Source : “\[Témoignage\] Peut-on (re)coder la loi ? L’exemple de la taxe d’habitation”, Etalab, URL :  [__https://www.etalab.gouv.fr/temoignage-peut-on-recoder-la-loi-lexemple-de-la-taxe-dhabitation__](https://www.etalab.gouv.fr/temoignage-peut-on-recoder-la-loi-lexemple-de-la-taxe-dhabitation) (consulté le 01/11/2023) |
| 15 | “Guide du Score Rein”, Pôle Qualité des Données, Agence de Biomédecine, URL : [__https://www.agence-biomedecine.fr/IMG/pdf/guide_score_rein_v1.pdf__](https://www.agence-biomedecine.fr/IMG/pdf/guide_score_rein_v1.pdf) (consulté le 01/11/2023) |
| 16 | Voir le projet en ligne, URl : [__https://algorithmliteracy.org__](https://algorithmliteracy.org) (consulté le 03/11/2023) |
| 17 | “DATA ISLAND. NAVIGUER DANS LE MONDE DES DONNÉES”, Fréquences Ecoles, URL :  [__https://www.frequence-ecoles.org/data-island-adultes__](https://www.frequence-ecoles.org/data-island-adultes) (consulté le 01/11/2023) |
| 18 | Voir à ce propos : “Shaping AI Systems By Shifting Power”, data & society, Medium, 18/10/2023. URL : [__https://medium.com/datasociety-points/shaping-ai-systems-by-shifting-power-ee95f7c3edf9__](https://medium.com/datasociety-points/shaping-ai-systems-by-shifting-power-ee95f7c3edf9) (consulté le 06/11/2023). |
